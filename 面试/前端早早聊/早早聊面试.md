



npm2
优点：
  结构清晰

缺点：
 重复依赖

yarn/npm3： 部分扁平

优点：
 不会出现重复的包，

缺点：
 幽灵依赖： 你可以使用不在package.JSON的声明的包
 依赖提升： 结构不稳定
 依赖树： 打平算法很复杂，所以相对也会占用时间
 依然是依赖于copy-paste方式，占用磁盘空间的方式

yarn：

1.优点：
  1.支持并行下载安装，npm只能串行
  2.支持离线模式，优先从本地缓存中取包代码
  3.```yarn set version`````切换版本，效果很向nvm
  4.yarn 2之后支持pnpm，效果有点像.pnpm.js文件  也是能够节省安装时间，磁盘大小

2.缺点：


Pnpm---Performance npm，全局只有一份代码副本（content-adressable store）,其他地方都是通过硬链、软链方式，链接过去的。

优点：
  1. 能够解决幽灵依赖和依赖提升
  2. 结构清晰
  3. 所有代码都是通过硬链接、软链方式链接到副本、不需要赋值、性能比较高、占用空间比较小

缺点：
  1.软链兼容性并不是特别好，electron，实测部分包会出错
  2.patch-package 不方便，全局只有一个副本


高阶： 自我思考

包管理： 在过去通过script标签来引入依赖，一直到node+npm才让这件事情变得相对优雅，导致应用的复杂度也相应的提升。
  通过软链的方式链接到.Pnpm里面的node_module


大文件上传方案：
问题：
1.文件大，上传时间就会变得更长，中间会出现很多幺蛾子（服务端负载、网络、超时、浏览器压力）
2.普通http，就很可能超时，重试成本非常高；
3.上传时间内，用户啥都做不了，最终体验非常差

基础：
1.化整为零：大人物拆解为多个小任务，一方面能够避免单个大任务超时，另一方面

具体方案；
1.切片： file.prototype.slice
2.计算每一个切片的顺序，hash[spark-md5],调用任务接口创建上传任务
  a.服务端记录这些任务信息
3.逐个切片发送到服务器
  a.服务端接收并转存这些切片，oss
  b.前端还需要计算上传进度（xhr的progress事件监听进度）
4.所有切片上传完毕之后，再按照索引组合这些分片

优化：
1. 切片：
  策略： 数量、大小
  file.prototype.stream() => ReaderStream
  分流： 分任务 worker stream
2.传输：
 1.多个http请求（注意并发数量、容易超时）、websocket提升并发度
 2.内容hash--所谓的秒传
 3.使用jszip去做压缩（多媒体资源下，效果较弱）
3.断点续传
  本地 indexed db（存储切片内容、索引、hash、任务id等信息）
  service worker
  暂停功能：
    借助xhr.abort/fetch 的 AbortController 实现暂停